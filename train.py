# -*- coding: utf-8 -*-
"""
Created on Sun Jul 21 18:33:28 2019

@author: myidispg
"""

import os
import torch

import numpy as np

from pycocotools.coco import COCO

from models.full_model import OpenPoseModel

import utilities.constants as constants
import utilities.helper as helper
from training_utilities.train_utils import train_epoch, train
from training_utilities.stancenet_dataset import StanceNetDataset

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# Read the pickle files into dictionaries.
#pickle_in = open(os.path.join(constants.dataset_dir, 'keypoints_train_new.pickle'), 'rb')
#keypoints_train = pickle.load(pickle_in)
#
#pickle_in = open(os.path.join(constants.dataset_dir, 'keypoints_val_new.pickle'), 'rb')
#keypoints_val = pickle.load(pickle_in)
#
#pickle_in.close()

print('Loading training COCO Annotations used for mask generation. Might take time.')
coco_train = COCO(os.path.join(os.path.join(os.getcwd(), 'Coco_Dataset'),
                       'annotations', 'person_keypoints_train2017.json'))

ann_ids = coco_train.getAnnIds()
anns = coco_train.loadAnns(ann_ids)
print('Annotation load complete.')

for ann in anns:
    mask = coco_train.annToMask(ann)
    
test = coco_train.loadAnns(ann_ids[0])
mask = coco_train.annToMask(test)

train_data = StanceNetDataset(coco_train, os.path.join(constants.dataset_dir, 'new_train2017'))
valid_data = StanceNetDataset(coco_train, anns, keypoints_val,
                              os.path.join(constants.dataset_dir, 'new_val2017'))

train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=2,
                                               shuffle=True)
valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=2,
                                               shuffle=True)

status = train(valid_dataloader, device, num_epochs=1, val_every=False,
               print_every=100, resume=False)
if status == None:
    print('There was some issue in the traiing process. Please check.')
    
import matplotlib.pyplot as plt
plt.plot(list(range(len(losses))), losses)
plt.xlabel('Epcohs')
plt.ylabel('Loss')

# Test an image
import cv2

img = cv2.imread(os.path.join(constants.dataset_dir, 'new_val2017', '000000000001.jpg'))
cv2.imshow('img', img)
cv2.waitKey()
cv2.destroyAllWindows()

img = img.reshape(1, -1, 224, 224)
outputs = model(torch.from_numpy(img).float().to(device))
conf = outputs[3]['conf'].cpu().detach().numpy().reshape(56, 56, -1)

def process_output_conf_map(image, scale_factor=4):
    """
    Returns the heatmap generated by model output is a visualizable form.
    Inputs:
        image: The heatmap generated by the model. Must be of shape:
            (batch, num_joints, im_width, im_height)
        scale_factor: The factor by which to enlarge the heatmap. Default=4
    """
    
    from utilities.helper import do_affine_transform
    
    print(image.shape)
    
    conf = np.zeros((image.shape[2], image.shape[3]))
    image = image.reshape(image.shape[2], image.shape[3], 17)
    for i in range(17):
        conf += image[:, :, i]
        
    conf = do_affine_transform(image, scale_factor)
    return conf

def visualize_output_conf_map(conf_map):
    """
    Visualizes a conf map using OpenCV.
    Inputs:
        conf_map: The conf_map to be visualized. Needs to be of the shape:
            (1, num_joints, width, height)
    """
    conf_map = process_output_conf_map(conf_map)
    cv2.imshow('COnfidence Map',conf_map)
    cv2.waitKey()
    cv2.destroyAllWindows()

visualize_output_conf_map(conf)
conf = process_output_conf_map(outputs[3]['conf'].cpu().detach().numpy())

disp = np.zeros((56, 56))
for i in range(17):
    disp += conf[:, :, i]

disp = helper.do_affine_transform(disp, 10)
    
cv2.imshow('disp', conf)
cv2.waitKey()
cv2.destroyAllWindows()